import torch
import torch.nn as nn
import intel_extension_for_pytorch as ipex
import time

# =================é…ç½®åŒº (åœ¨è¿™é‡Œè°ƒèŠ‚å‹åŠ›)=================
# 1. å¢åŠ å®½åº¦ï¼šçŸ©é˜µè¿ç®—é‡æ˜¯å®½åº¦çš„å¹³æ–¹çº§ã€‚4096 -> 8192 è®¡ç®—é‡ç¿»4å€
HIDDEN_DIM = 8192   
# 2. å¢åŠ æ·±åº¦ï¼šå±‚æ•°è¶Šå¤šï¼Œä¸²è¡Œè®¡ç®—è¶Šä¹…
NUM_LAYERS = 20     
# 3. å¢åŠ  Batch Sizeï¼šè¿™æ˜¯å¡«æ»¡è®¡ç®—å•å…ƒ(EU/Core)çš„å…³é”®ã€‚
#    å¦‚æœæ˜¾å­˜æº¢å‡º(OOM)ï¼Œè¯·å‡å°è¿™ä¸ªå€¼ï¼›å¦‚æœæ˜¾å­˜æ²¡æ»¡ï¼Œå¾€æ­»é‡ŒåŠ ã€‚
BATCH_SIZE = 2048   
# 4. æŒç»­å¾ªç¯æ¬¡æ•°ï¼šå•æ¬¡è¿è¡Œä¸å¤Ÿçƒ­ï¼Œå¿…é¡»æŒç»­è½°ç‚¸
LOOP_COUNT = 100    
# ========================================================

device = torch.device("xpu" if torch.xpu.is_available() else "cpu")
print(f"ğŸ”¥ Current Device: {device}")

# åŠ¨æ€æ„å»ºè¶…é‡æ¨¡å‹
class SuperHeavyModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layers):
        super().__init__()
        model_list = []
        # è¾“å…¥å±‚
        model_list.append(nn.Linear(input_dim, hidden_dim))
        model_list.append(nn.GELU())
        
        # ä¸­é—´å±‚ (å¤§é‡å †å )
        for _ in range(layers - 2):
            model_list.append(nn.Linear(hidden_dim, hidden_dim))
            model_list.append(nn.GELU()) # GELU åŒ…å« exp/tanh è¿ç®—ï¼Œæ¯” ReLU ç´¯
            
        # è¾“å‡ºå±‚
        model_list.append(nn.Linear(hidden_dim, hidden_dim))
        self.net = nn.Sequential(*model_list)

    def forward(self, x):
        return self.net(x)

print(f"ğŸ—ï¸ Building Model: {NUM_LAYERS} Layers, {HIDDEN_DIM} Width...")
model = SuperHeavyModel(4096, HIDDEN_DIM, NUM_LAYERS).to(device)
model.eval()

# æ•°æ®ç”Ÿæˆ (æ¶ˆè€—å¤§é‡å¸¦å®½)
print(f"ğŸ“¦ Generating Data (Batch: {BATCH_SIZE})...")
try:
    input_data = torch.randn(BATCH_SIZE, 4096, device=device)
except RuntimeError as e:
    print("âŒ æ˜¾å­˜ä¸è¶³ (OOM)ï¼Œè¯·å‡å° BATCH_SIZE æˆ– HIDDEN_DIM")
    raise e

# IPEX ä¼˜åŒ–
print("ğŸ› ï¸ Optimizing with IPEX (BF16)...")
try:
    model = ipex.optimize(model, dtype=torch.bfloat16)
    use_bf16 = True
except Exception:
    model = ipex.optimize(model)
    use_bf16 = False
    print("âš ï¸ Fallback to FP32")

# å‹åŠ›æµ‹è¯•ä¸»å¾ªç¯
print(f"ğŸš€ Starting Stress Loop ({LOOP_COUNT} iterations)...")
amp_device_type = "xpu" if device.type == "xpu" else "cpu"

# é¢„çƒ­
for _ in range(5):
    with torch.autocast(device_type=amp_device_type, enabled=use_bf16, dtype=torch.bfloat16):
        _ = model(input_data)

torch.xpu.synchronize() if device.type == "xpu" else None
start_time = time.time()

# æŒç»­è½°ç‚¸
for i in range(LOOP_COUNT):
    with torch.autocast(device_type=amp_device_type, enabled=use_bf16, dtype=torch.bfloat16):
        output = model(input_data)
    
    # æ¯ 50 æ¬¡åŒæ­¥ä¸€æ¬¡ï¼Œé˜²æ­¢ CPU è·‘å¤ªå¿« GPU é˜Ÿåˆ—å †ç§¯å¯¼è‡´æµ‹é‡ä¸å‡†ï¼Œ
    # ä½†ä¸ºäº†æœ€å¤§åŒ–å‹åŠ›ï¼Œé€šå¸¸ä¸éœ€è¦é¢‘ç¹åŒæ­¥ï¼Œåªéœ€è¦è®© GPU é˜Ÿåˆ—å¡æ»¡ã€‚
    if i % 1 == 0:
            # å¼ºåˆ¶ CPU ç­‰ GPU ç®—å®Œè¿™ä¸€æ­¥å†æ‰“å°ï¼Œè¿™æ ·è¿›åº¦æ¡å°±æ˜¯å®æ—¶çš„äº†
            torch.xpu.synchronize() 
            print(f"   Step {i}/{LOOP_COUNT} completed...")

# ç¡®ä¿æ‰€æœ‰è®¡ç®—å®Œæˆ
torch.xpu.synchronize() if device.type == "xpu" else None
end_time = time.time()
total_time = end_time - start_time

print(f"âœ… Stress Test Finished.")
print(f"â±ï¸ Total Time: {total_time:.2f}s")
print(f"âš¡ Throughput: {LOOP_COUNT / total_time:.2f} iter/s")